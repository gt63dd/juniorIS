% This is a template for your written document.
%
% To compile using latexmk on the command line, run the following: 
% latexmk -pdf main.tex

\documentclass[12pt]{article}
\usepackage{setspace}
\usepackage{graphicx} % used for includegraphics
\usepackage{tikz}
\usetikzlibrary{positioning}
\singlespace
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
	itle{\textbf{Detecting Reseller Bots in Limited Clothing Drops Using Risk Scoring and Navigation Patterns}}
\author{Godfred Tekpor}

\begin{document}

\maketitle

\section{Project Topic: Detecting Reseller Bots in Limited Clothing Drops Using Risk Scoring and Navigation Patterns}

\subsection{Motivation and Significance}
Limited-release clothing drops create extreme bursts of traffic and strong incentives for automation. Reseller bots attempt to gain an advantage by executing faster-than-human navigation paths (product $\rightarrow$ add-to-cart $\rightarrow$ checkout), polling inventory endpoints, and distributing attempts across many accounts or proxies. In practice, purely rule-based defenses (e.g., hard blocks and simple rate limits) are often either too weak against advanced bots or too costly for legitimate customers. This project focuses on a practical middle ground: a risk scoring system that estimates bot-likelihood from session navigation patterns and request timing, then applies calibrated mitigation only when needed.

Prior work shows that navigation and timing signals in web logs can be used to detect evasive bots, and that combining multiple evidence sources can improve robustness. Iliou et al.\ demonstrate that modeling sessions from web logs can be effective, and that adding human-interaction evidence (mouse behavior) raises attacker cost and improves detection under an “advanced bot” threat model \cite{Iliou2021DTRAP}. However, bot detection is not a static problem. Iliou et al.\ also show an adversarial dynamic where reinforcement-learning bots learn navigation behaviors that evade detectors trained on web-log features, and can re-adapt after the detector is retrained \cite{Iliou2022ARES}. This motivates designing a risk score that can be stress-tested against adaptive policies rather than only simple scripted bots. Finally, risk scoring is only valuable if it connects to mitigation decisions. Gangwal et al.\ propose a multi-barrier CAPTCHA mechanism that balances usability and security, suggesting a pathway for escalation when a session appears suspicious \cite{Gangwal2025SwissCheese}. Together, these sources motivate a layered approach: (1) score sessions using navigation patterns, (2) escalate friction for high-risk traffic, and (3) evaluate robustness under evasion.

\subsection{Goals and Contributions}
The project will produce a working software prototype (``DropGuard'') and an experimental evaluation. The main goals are:
\begin{enumerate}
	\item Build a small drop-style e-commerce site (product, cart, checkout) that records detailed session-level event logs.
	\item Implement multiple bot simulators representing distinct reseller behaviors (fast-path, burst/polling, stealth) and a human-session simulator.
	\item Design an interpretable risk scoring engine using navigation-path and request-timing features derived from web logs.
	\item Evaluate tradeoffs between security and user friction by comparing mitigation policies (allow, delay, throttle, challenge).
	\item Stress-test robustness by introducing adaptive behavior inspired by reinforcement-learning evasion results \cite{Iliou2022ARES}.
\end{enumerate}

The intended contribution is not to claim a universal defense against all automation, but to provide a measurable, reproducible study: which navigation-pattern features provide the most signal, how early scoring decisions can be made, and how mitigation choices shift outcomes (bot capture rate vs.\ legitimate user friction).

\subsection{Software Description}
DropGuard will be implemented in Python using FastAPI and a SQLite event store. The system will treat each visitor as a session with a unique session identifier. Each request (page view or API call) will be logged as an event with timestamp, endpoint, response status, and minimal metadata needed for analysis. A risk engine will periodically compute a session score in $[0,1]$ based on features such as:
\begin{itemize}
	\item \textbf{Speed features:} time from product-view to add-to-cart, add-to-cart to checkout, median inter-event gap.
	\item \textbf{Path features:} step skipping, repeated loops, unusually short navigation sequences.
	\item \textbf{Burstiness:} request rate spikes, polling frequency, retry patterns.
\end{itemize}
Mitigation will be applied at sensitive actions (add-to-cart and checkout). Low-risk sessions proceed normally; medium-risk sessions may be delayed or rate-limited; high-risk sessions may be challenged (e.g., a stronger interaction step) or throttled. This approach aligns with research showing that combined evidence and escalation can improve effectiveness while keeping the user experience reasonable \cite{Iliou2021DTRAP,Gangwal2025SwissCheese}.

\subsection{Evaluation Plan}
Experiments will simulate repeated ``drops'' with limited inventory and concurrent human and bot sessions. Metrics will include:
\begin{itemize}
	\item \textbf{Bot capture rate:} percentage of inventory purchased by bots.
	\item \textbf{Human success rate:} percentage of legitimate sessions completing checkout.
	\item \textbf{False positives:} legitimate sessions incorrectly challenged or throttled.
	\item \textbf{Friction cost:} added time to checkout and drop-off rate due to mitigation.
	\item \textbf{Robustness:} performance under stealth bots and adaptive behavior inspired by RL evasion \cite{Iliou2022ARES}.
\end{itemize}

\subsection{Logic Diagram}
Figure~\ref{fig:logic} shows the high-level flow of the system. The user interacts with the drop website, events are logged, a risk score is computed, and policy decides whether to allow, add friction, or throttle.

\begin{figure}[h]
\centering
\begin{tikzpicture}[node distance=14mm, every node/.style={font=\small}]
	ikzstyle{box}=[draw, rounded corners, align=center, minimum width=3.7cm, minimum height=0.9cm]
\node[box] (user) {User / Bot\\Client};
\node[box, below=of user] (site) {Drop Website\\(FastAPI)};
\node[box, below left=of site, xshift=-8mm] (log) {Event Logger\\(SQLite)};
\node[box, below right=of site, xshift=8mm] (risk) {Risk Engine\\(Navigation Features)};
\node[box, below=of risk] (policy) {Mitigation Policy\\Allow / Delay / Throttle / Challenge};

\draw[->] (user) -- node[right]{requests} (site);
\draw[->] (site) -- node[left]{events} (log);
\draw[->] (log) -- node[below]{session features} (risk);
\draw[->] (risk) -- node[right]{score} (policy);
\draw[->] (policy.west) .. controls +(left:18mm) and +(right:18mm) .. node[above]{decision} (site.east);
\end{tikzpicture}
\caption{DropGuard logic flow: navigation events $\rightarrow$ risk scoring $\rightarrow$ mitigation at sensitive actions.}
\label{fig:logic}
\end{figure}

% UI sketches
\begin{figure}[h]
\centering
\includegraphics[width=0.9\linewidth]{imgs/dropguard-ui.png}
\caption{Product page and cart summary sketch for a limited drop.}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.9\linewidth]{imgs/dropguard-dashboard.png}
\caption{Risk scoring dashboard sketch for live session monitoring.}
\end{figure}


\newpage
\appendix
\section{Feature List (Development Roadmap)}
\begin{enumerate}
	\item Implement product page endpoint and static product inventory model.
	\item Implement cart endpoints (add, remove, update quantity/size).
	\item Implement checkout endpoint and simulated ``purchase'' action that decrements inventory.
	\item Create session management (session ID cookies) for all clients.
	\item Implement structured event logging to SQLite (timestamp, session ID, endpoint, status, metadata).
	\item Implement feature extraction for navigation patterns from event logs (timing, path, burstiness).
	\item Implement risk scoring function returning a bot-likelihood score in $[0,1]$.
	\item Implement mitigation policy gates at add-to-cart and checkout based on risk score.
	\item Build bot simulator scripts: fast-path bot, burst/polling bot, stealth bot.
	\item Build a human-session simulator with realistic timing variance and navigation noise.
	\item Implement experiment runner to launch mixed populations and run repeated drop trials.
	\item Implement evaluation metrics and produce summary tables/plots (capture rate, false positives, friction).
	\item \textbf{Stretch:} Add an adaptive bot that tunes timing/path choices to reduce risk score (stress test).
	\item \textbf{Stretch:} Add a simple admin dashboard to visualize sessions, scores, and mitigation decisions.
\end{enumerate}


\bibliographystyle{acm}
\bibliography{bibliography.bib}

\end{document}
